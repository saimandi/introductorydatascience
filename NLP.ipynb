{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac31ef9",
   "metadata": {},
   "source": [
    "# Natural Language Processing(NLP)\n",
    "*The study of programming computers to understand human language as used in large bodies of text.*\n",
    "\n",
    "## Concepts\n",
    "\n",
    "## Implementation\n",
    "### Import NLTK(Natural Language Toolkit) package\n",
    "\n",
    "### Removing Stop Words\n",
    "- eliminating common language prepositions\n",
    "`{code-cell}\n",
    "\n",
    "`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc766811",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mnltk.download([\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m...     \"names\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m... ])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "\"\"\"\n",
    "nltk.download([\n",
    "...     \"names\",\n",
    "...     \"stopwords\",\n",
    "...     \"state_union\",\n",
    "...     \"twitter_samples\",\n",
    "...     \"movie_reviews\",\n",
    "...     \"averaged_perceptron_tagger\",\n",
    "...     \"vader_lexicon\",\n",
    "...     \"punkt\",\n",
    "... ])\n",
    "\"\"\"\n",
    "from nltk import NaiveBayesClassifier, classify\n",
    "from ntlk.stem.porter import PorterStemmer\n",
    "from ntlk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews, stopwords\n",
    "from random import shuffle \n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c58b7",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "- the splitting of a text block into individual words \n",
    " The movie review data set is already tokenized in that it has a column filled with words that are \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d34744",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I really do Love this Movie. I saw it on opening night and have no regrets. I will admit it is a bit slow at\n",
    "          the beginning but honestly I kind of liked that. It really showed his detective side. He is the world's \n",
    "          greatest detective and that isn't shown enough in my opinion. There are plenty of awesome fight scenes so \n",
    "          you get to see a that Batman. Matt Reeves continues to stun me with an amazing movie. Thinking of Dawn of \n",
    "          the Planet of the Apes and War for the Planet of the apes made no surprise to how amazing the Batman was. \n",
    "          Matt Reeves did an amazing job with the movie with hidden subtext to how Batman and Riddler are somewhat \n",
    "          similar. Every time Batman and Riddler meet each other it's through a glass or through a screen symbolizing \n",
    "          that they're a relfection of each other. There was so much depth and work Matt Reeves pu into the movie. The\n",
    "          acting was absolutely amazing. Like a lot of fans I was skeptical about the actors. But they blew my mind. \n",
    "          The acting and portrayal of every character was amazing! Robert Pattinson, Zoe Kravitz, Paul Dano, Jefferey \n",
    "          Wright, Colin Farrell, John Turturro, Andy Serkis, and every other actor in the movie was amazing.\"\"\"\n",
    "\n",
    "print(word_tokenize(text))\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1906a070",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "- removing suffixes and prefixes to get the root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d148861",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d8720",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed = [PorterStemmer().stem(w) for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcdb6e8",
   "metadata": {},
   "source": [
    "### Lematization\n",
    "- adjusting stemmed words according to grammatical rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmed = [WordNetLemmatizer().lemmatize(w) for w in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd826bd0",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "- the feature we are using to classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append((movie_reviews.words(fileid), category))\n",
    "print(len(documents))\n",
    "shuffle(documents)\n",
    "all_words = [word.lower() for word in movie_reviews.words()]\n",
    "all_words_frequency = FreqDist(all_words)\n",
    "stopwords_english = stopwords.words('english')\n",
    "print (stopwords_english)\n",
    "all_words_without_stopwords = [word for word in all_words if word not in stopwords_english]\n",
    "all_words_without_punctuation = [word for word in all_words if word not in string.punctuation]\n",
    "most_common_words = all_words_frequency.most_common(2000)\n",
    "\n",
    "def document_features(document):\n",
    "    # \"set\" function will remove repeated/duplicate tokens in the given list\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "movie_review_file = movie_reviews.fileids('neg')[0] \n",
    "feature_set = [(document_features(doc), category) for (doc, category) in documents]\n",
    "\n",
    "test_set = feature_set[:400]\n",
    "train_set = feature_set[400:]\n",
    "\n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2a6cc",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging\n",
    "\n",
    "There are a few interesting projects that can be done with NLP experience. A few of which are spamming detection, creating word clouds, and sentiment analysis. \n",
    "\n",
    "The main project I chose to focuz on today is sentiment analysis. The project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
